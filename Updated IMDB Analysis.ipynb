{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotnine'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12972/2371314330.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mplotnine\u001b[0m \u001b[1;32mimport\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotnine'"
     ]
    }
   ],
   "source": [
    "#Import libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the Data \n",
    "\n",
    "movie_df=pd.read_csv(\"/kaggle/input/imdb-5000-movie-dataset/movie_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying the first 10 records\n",
    "\n",
    "movie_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shape of the dataset (no of rows and no of columns)\n",
    "\n",
    "movie_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying the data type of the dataset attributes \n",
    "\n",
    "movie_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Five point summary for the numerical columns in the dataset\n",
    "\n",
    "movie_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the Imdb link from the dataset\n",
    "\n",
    "movie_df.drop('movie_imdb_link', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the color section as most of the movies is colored\n",
    "\n",
    "movie_df[\"color\"].value_counts()\n",
    "\n",
    "movie_df.drop('color',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for the columns present in the datset\n",
    "movie_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for the missing values in the dataset\n",
    "\n",
    "movie_df.isna().any()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No of the missing values in the dataset\n",
    "\n",
    "movie_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can remove the null values from the dataset where the count is less . so that we don't loose much data \n",
    "\n",
    "movie_df.dropna(axis=0,subset=['director_name', 'num_critic_for_reviews','duration','director_facebook_likes','actor_3_facebook_likes','actor_2_name','actor_1_facebook_likes','actor_1_name','actor_3_name','facenumber_in_poster','num_user_for_reviews','language','country','actor_2_facebook_likes','plot_keywords'],inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** I lost only 6% of the data which is acceptable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing the content rating with Value R as it has highest frequency\n",
    "\n",
    "movie_df[\"content_rating\"].fillna(\"R\", inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing the aspect_ratio with the median of the value as the graph is right skewed \n",
    "\n",
    "movie_df[\"aspect_ratio\"].fillna(movie_df[\"aspect_ratio\"].median(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to replace the value in budget with the median of the value\n",
    "\n",
    "movie_df[\"budget\"].fillna(movie_df[\"budget\"].median(),inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to replace the value in gross with the median of the value \n",
    "\n",
    "movie_df['gross'].fillna(movie_df['gross'].median(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recheck that all the null values are removed\n",
    "\n",
    "movie_df.isna().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We don't have any null values in the datset anymore**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the duplicate values in the datset\n",
    "\n",
    "movie_df.drop_duplicates(inplace=True)\n",
    "movie_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count of the language values \n",
    "\n",
    "movie_df[\"language\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**94 % of the movie is english**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphical presentaion \n",
    "plt.figure(figsize=(40,10))\n",
    "sns.countplot(movie_df[\"language\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Most of the values for the languages is english we can drop the english column\n",
    "\n",
    "movie_df.drop('language',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a new column to check the net profit made by the company (Gross-Budget) \n",
    "\n",
    "movie_df[\"Profit\"]=movie_df['budget'].sub(movie_df['gross'], axis = 0) \n",
    "\n",
    "movie_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a new column to check the profit percentage made by the company \n",
    "\n",
    "movie_df['Profit_Percentage']=(movie_df[\"Profit\"]/movie_df[\"gross\"])*100\n",
    "movie_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So we have added two new columns  profit and profit percentage made by the movies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Value counts for the countries \n",
    "\n",
    "value_counts=movie_df[\"country\"].value_counts()\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can see most of the movies are from USA ,UK and the rest of the countries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##get top 2 values of index\n",
    "vals = value_counts[:2].index\n",
    "print (vals)\n",
    "movie_df['country'] = movie_df.country.where(movie_df.country.isin(vals), 'other')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Successfully divided the country into three catogories \n",
    "movie_df[\"country\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Data Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for the movies released year wise \n",
    "\n",
    "(ggplot(movie_df)         # defining what data to use\n",
    " + aes(x='title_year')    # defining what variable to use\n",
    " + geom_bar(size=20) # defining the type of plot to use\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** We can see the most of the movies which are released after 1980 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relationship between the imdb score and the profit made by the movie \n",
    "\n",
    "ggplot(aes(x='imdb_score', y='Profit'), data=movie_df) +\\\n",
    "    geom_line() +\\\n",
    "    stat_smooth(colour='blue', span=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** We can see that there is strong corelation between the imdb_score and the profit . The movies with high imdb rating have made more profit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship between imdb score and profit percentage\n",
    "\n",
    "ggplot(aes(x='imdb_score', y='Profit'), data=movie_df) +\\\n",
    "    geom_line() +\\\n",
    "    stat_smooth(colour='blue', span=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Movies with high IMDB score has made more profit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for the imdb rating of the movies and compared with the countries  \n",
    "\n",
    "ggplot(aes(x='country', y='imdb_score'), data=movie_df) +\\\n",
    "    geom_line() +\\\n",
    "    stat_smooth(colour='blue', span=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Most of the movies above rating 8.75 are from USA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the corelation between imdb_rating with respect to no of facebook likes \n",
    "\n",
    "(ggplot(movie_df)\n",
    " + aes(x='imdb_score', y='movie_facebook_likes')\n",
    " + geom_line()\n",
    " + labs(title='IMDB_Score vs. Facebook like for Movies', x='IMDB scores', y='Facebook Likes for movies')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Movie with high IMDB rating have most no of facebook likes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 20 movies based on the profit they made\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "movie_df= movie_df.sort_values(by ='Profit' , ascending=False)\n",
    "movie_df_new=movie_df.head(20)\n",
    "ax=sns.pointplot(movie_df_new['Profit'], movie_df_new['budget'], hue=movie_df_new['movie_title'])\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 20 movies based on the profit percentage\n",
    "plt.figure(figsize=(10,8))\n",
    "movie_df= movie_df.sort_values(by ='Profit_Percentage' , ascending=False)\n",
    "movie_df_new=movie_df.head(20)\n",
    "ax=sns.pointplot(movie_df_new['Profit_Percentage'], movie_df_new['budget'], hue=movie_df_new['movie_title'])\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 20 directors based on the IMDB ratings\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "movie_df= movie_df.sort_values(by ='imdb_score' , ascending=False)\n",
    "movie_df_new=movie_df.head(20)\n",
    "ax=sns.pointplot(movie_df_new['director_name'], movie_df_new['imdb_score'], hue=movie_df_new['movie_title'])\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Commercial success vs critial acclaim\n",
    "movie_df= movie_df.sort_values(by ='Profit_Percentage' , ascending=False)\n",
    "movie_df_new=movie_df.head(20)\n",
    "(ggplot(movie_df_new)\n",
    " + aes(x='imdb_score', y='gross',color = \"content_rating\")\n",
    " + geom_point()\n",
    " +  geom_hline(aes(yintercept = 600)) + \n",
    "  geom_vline(aes(xintercept = 10)) + \n",
    "  xlab(\"Imdb score\") + \n",
    "  ylab(\"Gross money earned in million dollars\") + \n",
    "  ggtitle(\"Commercial success Vs Critical acclaim\") +\n",
    "  annotate(\"text\", x = 8.5, y = 700, label = \"High ratings \\n & High gross\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Movies with High content rating were not commercial success**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 20 actors of movies based on the commerical success\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "movie_df= movie_df.sort_values(by ='Profit_Percentage' , ascending=False)\n",
    "movie_df_new=movie_df.head(20)\n",
    "ax=sns.pointplot(movie_df_new['actor_1_name'], movie_df_new['Profit_Percentage'], hue=movie_df_new['movie_title'])\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 20 actors of movies based on the imdb rating of the movies \n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "movie_df= movie_df.sort_values(by ='imdb_score' , ascending=False)\n",
    "movie_df_new=movie_df.head(20)\n",
    "ax=sns.pointplot(movie_df_new['actor_1_name'], movie_df_new['imdb_score'], hue=movie_df_new['movie_title'])\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Country of Top 20 movies based on imdb rating\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "movie_df= movie_df.sort_values(by ='imdb_score' , ascending=False)\n",
    "movie_df_new=movie_df.head(20)\n",
    "ax=sns.pointplot(movie_df_new['country'], movie_df_new['imdb_score'], hue=movie_df_new['movie_title'])\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.Data Preparation for the models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1 Removing the Columns with names** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the director name column\n",
    "\n",
    "movie_df.drop('director_name', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the actor1 ,actor 2 and actor 3 names \n",
    "\n",
    "movie_df.drop('actor_1_name',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df.drop('actor_2_name',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df.drop('actor_3_name',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the movie title \n",
    "\n",
    "movie_df.drop('movie_title',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the plot keywords\n",
    "movie_df.drop('plot_keywords',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Value count of genres\n",
    "\n",
    "movie_df['genres'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Most of the values are equally distributed in genres column ,so we can remove the genres column\n",
    "\n",
    "movie_df.drop('genres',axis=1,inplace =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2 Remove the linear dependant variables****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropiing the profit column from the dataset\n",
    "movie_df.drop('Profit',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the profit percentage column from the dataset\n",
    "\n",
    "movie_df.drop('Profit_Percentage',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.3 Remove the coreelated variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with heat map\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "corr = movie_df.corr()\n",
    "sns.set_context(\"notebook\", font_scale=1.0, rc={\"lines.linewidth\": 2.5})\n",
    "plt.figure(figsize=(13,7))\n",
    "# create a mask so we only see the correlation values once\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask, 1)] = True\n",
    "a = sns.heatmap(corr,mask=mask, annot=True, fmt='.2f')\n",
    "rotx = a.set_xticklabels(a.get_xticklabels(), rotation=90)\n",
    "roty = a.set_yticklabels(a.get_yticklabels(), rotation=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ratio of the ratio of num_user_for_reviews and num_critic_for_reviews.\n",
    "\n",
    "movie_df['critic_review_ratio']=movie_df['num_critic_for_reviews']/movie_df['num_user_for_reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the num_critic_for_review\n",
    "\n",
    "movie_df.drop('num_critic_for_reviews',axis=1,inplace=True)\n",
    "movie_df.drop('num_user_for_reviews',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Correlation matrix shown in the figure \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "corr = movie_df.corr()\n",
    "sns.set_context(\"notebook\", font_scale=1.0, rc={\"lines.linewidth\": 2.5})\n",
    "plt.figure(figsize=(13,7))\n",
    "# create a mask so we only see the correlation values once\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask, 1)] = True\n",
    "a = sns.heatmap(corr,mask=mask, annot=True, fmt='.2f')\n",
    "rotx = a.set_xticklabels(a.get_xticklabels(), rotation=90)\n",
    "roty = a.set_yticklabels(a.get_yticklabels(), rotation=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see none of the attributes are not much correlated to each other.All are below 0.7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to categorize the imdb values in the range of 0-4,4-6,6-8 and 8-10 to mark them as the bad,average,good and excellent movies respectively\n",
    "\n",
    "movie_df[\"imdb_binned_score\"]=pd.cut(movie_df['imdb_score'], bins=[0,4,6,8,10], right=True, labels=False)+1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the imdb_score column as it is being replaced with the imdb_binned_score values \n",
    "movie_df.drop('imdb_score',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Handling the categorical data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = pd.get_dummies(data = movie_df, columns = ['country'] , prefix = ['country'] , drop_first = True)\n",
    "movie_df = pd.get_dummies(data = movie_df, columns = ['content_rating'] , prefix = ['content_rating'] , drop_first = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 6. Splitting the data into training and test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X=pd.DataFrame(columns=['duration','director_facebook_likes','actor_1_facebook_likes','gross','num_voted_users','facenumber_in_poster','budget','title_year','aspect_ratio','movie_facebook_likes','Other_actor_facebbok_likes','critic_review_ratio','country_USA','country_other','content_rating_G','content_rating_GP','content_rating_M','content_rating_NC-17','content_rating_Not Rated','content_rating_PG','content_rating_PG-13','content_rating_Passed','content_rating_R','content_rating_TV-14','content_rating_TV-G','content_rating_TV-PG','content_rating_Unrated','content_rating_X'],data=movie_df)\n",
    "y=pd.DataFrame(columns=['imdb_binned_score'],data=movie_df)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.3,random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.Feature scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Classification Model Selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.1 Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logit =LogisticRegression()\n",
    "logit.fit(X_train,np.ravel(y_train,order='C'))\n",
    "y_pred=logit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix for logistic regression**\n",
    "\n",
    "from sklearn import metrics\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(cnf_matrix)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.2 KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=22)\n",
    "knn.fit(X_train, np.ravel(y_train,order='C'))\n",
    "knnpred = knn.predict(X_test)\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, knnpred)\n",
    "print(cnf_matrix)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, knnpred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.3 SVC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC\n",
    "from sklearn.svm import SVC\n",
    "svc= SVC(kernel = 'sigmoid')\n",
    "svc.fit(X_train, np.ravel(y_train,order='C'))\n",
    "svcpred = svc.predict(X_test)\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, svcpred)\n",
    "print(cnf_matrix)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, svcpred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.4 Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive bayes\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gaussiannb= GaussianNB()\n",
    "gaussiannb.fit(X_train, np.ravel(y_train,order='C'))\n",
    "gaussiannbpred = gaussiannb.predict(X_test)\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, gaussiannbpred)\n",
    "print(cnf_matrix)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, gaussiannbpred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.5 Decision Tree**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier(criterion='gini') #criterion = entopy, gini\n",
    "dtree.fit(X_train, np.ravel(y_train,order='C'))\n",
    "dtreepred = dtree.predict(X_test)\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, dtreepred)\n",
    "print(cnf_matrix)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, dtreepred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.6 Ada Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ada Boosting\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "abcl = AdaBoostClassifier(base_estimator=dtree, n_estimators=60)\n",
    "abcl=abcl.fit(X_train,np.ravel(y_train,order='C'))\n",
    "abcl_pred=abcl.predict(X_test)\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, abcl_pred)\n",
    "print(cnf_matrix)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, abcl_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.7 Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators = 200)#criterion = entopy,gini\n",
    "rfc.fit(X_train, np.ravel(y_train,order='C'))\n",
    "rfcpred = rfc.predict(X_test)\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, rfcpred)\n",
    "print(cnf_matrix)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, rfcpred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.8 Bagging Classifier**[](http://)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_movie_df=movie_df.pop(\"imdb_binned_score\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bagging classfier\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bgcl = BaggingClassifier(n_estimators=60, max_samples=.7 , oob_score=True)\n",
    "\n",
    "bgcl = bgcl.fit(movie_df, new_movie_df)\n",
    "print(bgcl.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.9 Gradient Boosting**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient boosting\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbcl = GradientBoostingClassifier(n_estimators = 50, learning_rate = 0.09, max_depth=5)\n",
    "gbcl = gbcl.fit(X_train,np.ravel(y_train,order='C'))\n",
    "test_pred = gbcl.predict(X_test)\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, test_pred)\n",
    "print(cnf_matrix)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.10 XGBooosting**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, np.ravel(y_train,order='C'))\n",
    "xgbprd = xgb.predict(X_test)\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, xgbprd)\n",
    "print(cnf_matrix)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, xgbprd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9.Model Comparison**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print('Logistic  Reports\\n',classification_report(y_test, y_pred))\n",
    "print('KNN Reports\\n',classification_report(y_test, knnpred))\n",
    "print('SVC Reports\\n',classification_report(y_test, svcpred))\n",
    "print('Naive BayesReports\\n',classification_report(y_test, gaussiannbpred))\n",
    "print('Decision Tree Reports\\n',classification_report(y_test, dtreepred))\n",
    "print('Ada Boosting\\n',classification_report(y_test, abcl_pred))\n",
    "print('Random Forests Reports\\n',classification_report(y_test, rfcpred))\n",
    "print('Bagging Clasifier',bgcl.oob_score_) \n",
    "print('Gradient Boosting',classification_report(y_test, test_pred))\n",
    "print('XGBoosting\\n',classification_report(y_test, xgbprd))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
